{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "alike-morgan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:24:33.293193800Z",
     "start_time": "2023-06-28T19:24:32.996160700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-knitting",
   "metadata": {},
   "source": [
    "# Load the dataset for recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "victorian-bottom",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:24:35.024319800Z",
     "start_time": "2023-06-28T19:24:34.705756200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>term</th>\n      <th>length_of_stay_bucket</th>\n      <th>rate_plan</th>\n      <th>room_segment</th>\n      <th>n_people_bucket</th>\n      <th>weekend_stay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>WinterVacation</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[260-360]</td>\n      <td>[5-inf]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>WinterVacation</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[3-4]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2</td>\n      <td>WinterVacation</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[2-2]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3</td>\n      <td>WinterVacation</td>\n      <td>[4-7]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[3-4]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>4</td>\n      <td>WinterVacation</td>\n      <td>[4-7]</td>\n      <td>Standard</td>\n      <td>[0-160]</td>\n      <td>[2-2]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>5</td>\n      <td>Easter</td>\n      <td>[4-7]</td>\n      <td>Standard</td>\n      <td>[260-360]</td>\n      <td>[5-inf]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>6</td>\n      <td>OffSeason</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[260-360]</td>\n      <td>[5-inf]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>7</td>\n      <td>HighSeason</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[1-1]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>8</td>\n      <td>HighSeason</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[0-160]</td>\n      <td>[1-1]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8</td>\n      <td>7</td>\n      <td>HighSeason</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[1-1]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>8</td>\n      <td>7</td>\n      <td>HighSeason</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[1-1]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>9</td>\n      <td>HighSeason</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[3-4]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>9</td>\n      <td>HighSeason</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[3-4]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>12</td>\n      <td>10</td>\n      <td>HighSeason</td>\n      <td>[8-inf]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[3-4]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>11</td>\n      <td>LowSeason</td>\n      <td>[2-3]</td>\n      <td>Standard</td>\n      <td>[160-260]</td>\n      <td>[5-inf]</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data\", \"hotel_data\")\n",
    "\n",
    "interactions_df = pd.read_csv(os.path.join(data_path, \"hotel_data_interactions_df.csv\"), index_col=0)\n",
    "\n",
    "base_item_features = ['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay']\n",
    "\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "\n",
    "interactions_df.loc[:, 'term'] = pd.Categorical(\n",
    "    interactions_df['term'], categories=column_values_dict['term'])\n",
    "interactions_df.loc[:, 'length_of_stay_bucket'] = pd.Categorical(\n",
    "    interactions_df['length_of_stay_bucket'], categories=column_values_dict['length_of_stay_bucket'])\n",
    "interactions_df.loc[:, 'rate_plan'] = pd.Categorical(\n",
    "    interactions_df['rate_plan'], categories=column_values_dict['rate_plan'])\n",
    "interactions_df.loc[:, 'room_segment'] = pd.Categorical(\n",
    "    interactions_df['room_segment'], categories=column_values_dict['room_segment'])\n",
    "interactions_df.loc[:, 'n_people_bucket'] = pd.Categorical(\n",
    "    interactions_df['n_people_bucket'], categories=column_values_dict['n_people_bucket'])\n",
    "interactions_df.loc[:, 'weekend_stay'] = interactions_df['weekend_stay'].astype('str')\n",
    "interactions_df.loc[:, 'weekend_stay'] = pd.Categorical(\n",
    "    interactions_df['weekend_stay'], categories=column_values_dict['weekend_stay'])\n",
    "\n",
    "display(HTML(interactions_df.head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-third",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical user features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based user features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "variable-jaguar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:24:36.812768Z",
     "start_time": "2023-06-28T19:24:36.490485300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WinterVacation', 'OffSeason', 'HighSeason', 'LowSeason', '[2-3]', '[4-7]', 'Standard', 'Nonref', '[0-160]', '[160-260]', '[260-360]', '[2-2]', '[3-4]', 'True', 'False']\n"
     ]
    },
    {
     "data": {
      "text/plain": "       user_id  WinterVacation  OffSeason  HighSeason  LowSeason  [2-3]  \\\n0            1               1          0           0          0      1   \n42          50               0          1           0          0      1   \n333        706               1          0           0          0      1   \n569        115               0          1           0          0      0   \n1350      1736               0          1           0          0      0   \n2967        96               0          0           1          0      1   \n12667     7779               0          1           0          0      0   \n\n       [4-7]  Standard  Nonref  [0-160]  [160-260]  [260-360]  [2-2]  [3-4]  \\\n0          0         1       0        0          0          1      0      0   \n42         0         1       0        0          1          0      0      0   \n333        0         1       0        0          1          0      0      0   \n569        1         1       0        0          1          0      0      0   \n1350       1         0       1        0          1          0      1      0   \n2967       0         0       1        0          1          0      0      1   \n12667      1         1       0        0          1          0      0      1   \n\n       True  False  \n0         1      0  \n42        1      0  \n333       0      1  \n569       0      1  \n1350      1      0  \n2967      1      0  \n12667     1      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>WinterVacation</th>\n      <th>OffSeason</th>\n      <th>HighSeason</th>\n      <th>LowSeason</th>\n      <th>[2-3]</th>\n      <th>[4-7]</th>\n      <th>Standard</th>\n      <th>Nonref</th>\n      <th>[0-160]</th>\n      <th>[160-260]</th>\n      <th>[260-360]</th>\n      <th>[2-2]</th>\n      <th>[3-4]</th>\n      <th>True</th>\n      <th>False</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>50</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>706</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>569</th>\n      <td>115</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <td>1736</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2967</th>\n      <td>96</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12667</th>\n      <td>7779</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_users_df(interactions_df):\n",
    "\n",
    "    # Write your code here\n",
    "    users_df = interactions_df.drop(columns=['item_id'], errors='ignore')\n",
    "    users_df = pd.get_dummies(users_df, columns=['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay'], prefix='', prefix_sep='')\n",
    "    users_df = users_df.drop_duplicates(subset = [\"user_id\"])\n",
    "    drop_values = []\n",
    "\n",
    "    for column_name in interactions_df.columns[2:]:\n",
    "        num_of_unique_values = interactions_df[column_name].nunique()\n",
    "        if num_of_unique_values > 2:\n",
    "            top_num = int(num_of_unique_values/2)\n",
    "            worst_values = interactions_df[column_name].value_counts().sort_values(ascending=True).head(top_num).index\n",
    "            for v in worst_values:\n",
    "                drop_values.append(v)\n",
    "\n",
    "\n",
    "    users_df.drop(drop_values, axis=1, inplace=True)\n",
    "    users_df.add_prefix('user_')\n",
    "    user_features = users_df.columns.values[1:].tolist()\n",
    "\n",
    "    return users_df, user_features\n",
    "\n",
    "\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "print(user_features)\n",
    "\n",
    "display(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-keyboard",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical item features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based item features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "formal-munich",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:24:38.992742400Z",
     "start_time": "2023-06-28T19:24:38.517781100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['term_WinterVacation', 'term_Easter', 'term_OffSeason', 'term_HighSeason', 'term_LowSeason', 'term_MayLongWeekend', 'term_NewYear', 'term_Christmas', 'length_of_stay_bucket_[0-1]', 'length_of_stay_bucket_[2-3]', 'length_of_stay_bucket_[4-7]', 'length_of_stay_bucket_[8-inf]', 'rate_plan_Standard', 'rate_plan_Nonref', 'room_segment_[0-160]', 'room_segment_[160-260]', 'room_segment_[260-360]', 'room_segment_[360-500]', 'room_segment_[500-900]', 'n_people_bucket_[1-1]', 'n_people_bucket_[2-2]', 'n_people_bucket_[3-4]', 'n_people_bucket_[5-inf]', 'weekend_stay_True', 'weekend_stay_False']\n"
     ]
    },
    {
     "data": {
      "text/plain": "   item_id  term_WinterVacation  term_Easter  term_OffSeason  term_HighSeason  \\\n0        0                    1            0               0                0   \n1        1                    1            0               0                0   \n2        2                    1            0               0                0   \n3        3                    1            0               0                0   \n4        4                    1            0               0                0   \n5        5                    0            1               0                0   \n6        6                    0            0               1                0   \n\n   term_LowSeason  term_MayLongWeekend  term_NewYear  term_Christmas  \\\n0               0                    0             0               0   \n1               0                    0             0               0   \n2               0                    0             0               0   \n3               0                    0             0               0   \n4               0                    0             0               0   \n5               0                    0             0               0   \n6               0                    0             0               0   \n\n   length_of_stay_bucket_[0-1]  ...  room_segment_[160-260]  \\\n0                            0  ...                       0   \n1                            0  ...                       1   \n2                            0  ...                       1   \n3                            0  ...                       1   \n4                            0  ...                       0   \n5                            0  ...                       0   \n6                            0  ...                       0   \n\n   room_segment_[260-360]  room_segment_[360-500]  room_segment_[500-900]  \\\n0                       1                       0                       0   \n1                       0                       0                       0   \n2                       0                       0                       0   \n3                       0                       0                       0   \n4                       0                       0                       0   \n5                       1                       0                       0   \n6                       1                       0                       0   \n\n   n_people_bucket_[1-1]  n_people_bucket_[2-2]  n_people_bucket_[3-4]  \\\n0                      0                      0                      0   \n1                      0                      0                      1   \n2                      0                      1                      0   \n3                      0                      0                      1   \n4                      0                      1                      0   \n5                      0                      0                      0   \n6                      0                      0                      0   \n\n   n_people_bucket_[5-inf]  weekend_stay_True  weekend_stay_False  \n0                        1                  1                   0  \n1                        0                  1                   0  \n2                        0                  0                   1  \n3                        0                  1                   0  \n4                        0                  1                   0  \n5                        1                  0                   1  \n6                        1                  1                   0  \n\n[7 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>term_WinterVacation</th>\n      <th>term_Easter</th>\n      <th>term_OffSeason</th>\n      <th>term_HighSeason</th>\n      <th>term_LowSeason</th>\n      <th>term_MayLongWeekend</th>\n      <th>term_NewYear</th>\n      <th>term_Christmas</th>\n      <th>length_of_stay_bucket_[0-1]</th>\n      <th>...</th>\n      <th>room_segment_[160-260]</th>\n      <th>room_segment_[260-360]</th>\n      <th>room_segment_[360-500]</th>\n      <th>room_segment_[500-900]</th>\n      <th>n_people_bucket_[1-1]</th>\n      <th>n_people_bucket_[2-2]</th>\n      <th>n_people_bucket_[3-4]</th>\n      <th>n_people_bucket_[5-inf]</th>\n      <th>weekend_stay_True</th>\n      <th>weekend_stay_False</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows Ã— 26 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_items_df(interactions_df):\n",
    "\n",
    "    # Write your code here\n",
    "    items_df = interactions_df.drop(columns=['user_id'], errors='ignore')\n",
    "    items_df = pd.get_dummies(items_df, columns=['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay'])\n",
    "    items_df = items_df.drop_duplicates(subset = [\"item_id\"])\n",
    "    item_features = items_df.columns.values[1:].tolist()\n",
    "\n",
    "    return items_df, item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "print(item_features)\n",
    "\n",
    "display(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-imaging",
   "metadata": {},
   "source": [
    "# Neural network recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Code a recommender based on a neural network model. You are free to choose any network architecture you find appropriate. The network can use the interaction vectors for users and items, embeddings of users and items, as well as user and item features (you can use the features you developed in the first project).\n",
    "\n",
    "Remember to keep control over randomness - in the init method add the seed as a parameter and initialize the random seed generator with that seed (both for numpy and pytorch):\n",
    "\n",
    "```python\n",
    "self.seed = seed\n",
    "self.rng = np.random.RandomState(seed=seed)\n",
    "```\n",
    "in the network model:\n",
    "```python\n",
    "self.seed = torch.manual_seed(seed)\n",
    "```\n",
    "\n",
    "You are encouraged to experiment with:\n",
    "  - the number of layers in the network, the number of neurons and different activation functions,\n",
    "  - different optimizers and their parameters,\n",
    "  - batch size and the number of epochs,\n",
    "  - embedding layers,\n",
    "  - content-based features of both users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "unlike-recipient",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T20:17:33.438537Z",
     "start_time": "2023-06-28T20:17:33.180844Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from recommenders.recommender import Recommender\n",
    "\n",
    "class NNRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Linear recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5):\n",
    "        \"\"\"\n",
    "        Initialize recommender params and variables.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = None\n",
    "        self.n_neg_per_pos = n_neg_per_pos\n",
    "        self.recommender_df = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        self.users_df = None\n",
    "        self.user_features = None\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "def fit(self, interactions_df, users_df, items_df):\n",
    "    \"\"\"\n",
    "    Training of the recommender.\n",
    "\n",
    "    :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items\n",
    "        defined by user_id, item_id and features of the interaction.\n",
    "    :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "    :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "    \"\"\"\n",
    "\n",
    "    interactions_df = interactions_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "    users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "    self.users_df = users_df\n",
    "    self.user_features = user_features\n",
    "\n",
    "    items_df, item_features = prepare_items_df(interactions_df)\n",
    "    items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "\n",
    "\n",
    "\n",
    "    interactions_df = interactions_df.loc[:, ['user_id', 'item_id']]\n",
    "\n",
    "    interactions_df.loc[:, 'interacted'] = 1\n",
    "\n",
    "\n",
    "    user_id_mapping = {user_id: i for i, user_id in enumerate(interactions_df['user_id'].unique())}\n",
    "    item_id_mapping = {item_id: i for i, item_id in enumerate(interactions_df['item_id'].unique())}\n",
    "\n",
    "    self.user_id_mapping = user_id_mapping\n",
    "    self.item_id_mapping = item_id_mapping\n",
    "\n",
    "    interactions_df['user_id'] = interactions_df['user_id'].map(user_id_mapping)\n",
    "    interactions_df['item_id'] = interactions_df['item_id'].map(item_id_mapping)\n",
    "\n",
    "\n",
    "    negative_interactions = self.generate_negative_interactions(interactions_df)\n",
    "    negative_interactions['interacted'] = 0\n",
    "\n",
    "    interactions_df = pd.concat([interactions_df, negative_interactions], ignore_index=True)\n",
    "\n",
    "    interactions_df = pd.merge(interactions_df, users_df, on='user_id', how='left')\n",
    "    interactions_df = pd.merge(interactions_df, items_df, on='item_id', how='left')\n",
    "\n",
    "\n",
    "    inputs = torch.Tensor(interactions_df.drop(columns=['user_id', 'item_id', 'interacted']).values.astype('float32'))\n",
    "    labels = torch.Tensor(interactions_df['interacted'].values.reshape(-1, 1).astype('float32'))\n",
    "    input_dim = len(user_features) + len(item_features)\n",
    "    hidden_dim = 60\n",
    "\n",
    "    self.model = nn.Sequential(\n",
    "        nn.Linear(input_dim, hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, 1)\n",
    "    )\n",
    "    mse = nn.MSELoss()\n",
    "    optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "    num_epochs = 12\n",
    "    batch_size = 30\n",
    "    num_batches = len(inputs) / batch_size\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in range(num_batches):\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_inputs = inputs[start:end]\n",
    "            batch_labels = labels[start:end]\n",
    "            outputs = self.model(batch_inputs)\n",
    "            loss = mse(outputs, batch_labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "\n",
    "    self.recommender_df = self.recommender_df[:0]\n",
    "\n",
    "    items_df = items_df.copy()\n",
    "    items_df['item_id'] = items_df['item_id'].map(self.item_id_mapping)\n",
    "\n",
    "    for ix, user in users_df.iterrows():\n",
    "        recommendations = []\n",
    "        user_id = user['user_id']\n",
    "\n",
    "        if user_id in self.user_id_mapping:\n",
    "            mapped_user_id = self.user_id_mapping[user_id]\n",
    "\n",
    "\n",
    "            scores = []\n",
    "\n",
    "            chosen_pos = np.argsort(-scores)[:n_recommendations]\n",
    "\n",
    "            for item_pos in chosen_pos:\n",
    "                item_id = items_df.loc[item_pos, 'item_id']\n",
    "                score = scores[item_pos]\n",
    "\n",
    "                recommendations.append({\n",
    "                    'user_id': user_id,\n",
    "                    'item_id': item_id,\n",
    "                    'score': score\n",
    "                })\n",
    "\n",
    "        self.recommender_df = self.recommender_df.append(recommendations, ignore_index=True)\n",
    "\n",
    "    return self.recommender_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-relative",
   "metadata": {},
   "source": [
    "# Quick test of the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "greatest-canon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T20:17:35.146011100Z",
     "start_time": "2023-06-28T20:17:34.748339600Z"
    }
   },
   "outputs": [],
   "source": [
    "items_df = interactions_df.loc[:, ['item_id'] + base_item_features].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "initial-capital",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T20:17:35.907758800Z",
     "start_time": "2023-06-28T20:17:35.625907200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit method\n",
    "nn_recommender = NNRecommender()\n",
    "nn_recommender.fit(interactions_df, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "digital-consolidation",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T20:17:36.781186400Z",
     "start_time": "2023-06-28T20:17:36.445984100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>score</th>\n      <th>term</th>\n      <th>length_of_stay_bucket</th>\n      <th>rate_plan</th>\n      <th>room_segment</th>\n      <th>n_people_bucket</th>\n      <th>weekend_stay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>3</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>5</td>\n      <td>-1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recommender method\n",
    "\n",
    "recommendations = nn_recommender.recommend(pd.DataFrame([[1], [2], [3], [4], [5]], columns=['user_id']), items_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, items_df, on='item_id', how='left')\n",
    "display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-eleven",
   "metadata": {},
   "source": [
    "# Tuning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit\n",
    "\n",
    "seed = 6789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import traceback\n",
    "\n",
    "def tune_recommender(recommender_class, interactions_df, items_df, \n",
    "                     param_space, max_evals=1, show_progressbar=True, seed=6789):\n",
    "    # Split into train_validation and test sets\n",
    "\n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    train_validation = interactions_df.iloc[shuffle[:split_index]]\n",
    "    test = interactions_df.iloc[shuffle[split_index:]]\n",
    "\n",
    "    # Tune\n",
    "\n",
    "    def loss(tuned_params):\n",
    "        recommender = recommender_class(seed=seed, **tuned_params)\n",
    "        hr1, hr3, hr5, hr10, ndcg1, ndcg3, ndcg5, ndcg10 = evaluate_train_test_split_implicit(\n",
    "            recommender, train_validation, items_df, seed=seed)\n",
    "        return -hr10\n",
    "\n",
    "    n_tries = 1\n",
    "    succeded = False\n",
    "    try_id = 0\n",
    "    while not succeded and try_id < n_tries:\n",
    "        try:\n",
    "            trials = Trials()\n",
    "            best_param_set = fmin(loss, space=param_space, algo=tpe.suggest, \n",
    "                                  max_evals=max_evals, show_progressbar=show_progressbar, trials=trials, verbose=True)\n",
    "            succeded = True\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            try_id += 1\n",
    "            \n",
    "    if not succeded:\n",
    "        return None\n",
    "        \n",
    "    # Validate\n",
    "    \n",
    "    recommender = recommender_class(seed=seed, **best_param_set)\n",
    "\n",
    "    results = [[recommender_class.__name__] + list(evaluate_train_test_split_implicit(\n",
    "        recommender, {'train': train_validation, 'test': test}, items_df, seed=seed))]\n",
    "\n",
    "    results = pd.DataFrame(results, \n",
    "                           columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "    display(HTML(results.to_html()))\n",
    "    \n",
    "    return best_param_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-switzerland",
   "metadata": {},
   "source": [
    "## Tuning of the recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Tune your model using the code below. You only need to put the class name of your recommender and choose an appropriate parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.quniform('n_neg_per_pos', 1, 10, 1),\n",
    "    ########################\n",
    "    # Write your code here #\n",
    "    ########################\n",
    "}\n",
    "\n",
    "best_param_set = tune_recommender(NNRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=10, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-strap",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Run the final evaluation of your recommender and present its results against the Amazon and Netflix recommenders' results. You just need to give the class name of your recommender and its tuned parameters below.\n",
    "\n",
    "It's optional, but for better effect you can include here the results from all recommenders created during in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "given-homework",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T18:36:11.331231100Z",
     "start_time": "2023-06-27T18:36:10.939713300Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_train_test_split_implicit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m nn_recommender \u001B[38;5;241m=\u001B[39m NNRecommender(n_neg_per_pos\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Initialize your recommender here\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Give the name of your recommender in the line below\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m nn_tts_results \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNNRecommender\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[43mevaluate_train_test_split_implicit\u001B[49m(\n\u001B[0;32m      5\u001B[0m     nn_recommender, interactions_df, items_df))]\n\u001B[0;32m      7\u001B[0m nn_tts_results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\n\u001B[0;32m      8\u001B[0m     nn_tts_results, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecommender\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHR@1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHR@3\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHR@5\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHR@10\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNDCG@1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNDCG@3\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNDCG@5\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNDCG@10\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     10\u001B[0m display(HTML(nn_tts_results\u001B[38;5;241m.\u001B[39mto_html()))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'evaluate_train_test_split_implicit' is not defined"
     ]
    }
   ],
   "source": [
    "nn_recommender = NNRecommender(n_neg_per_pos=1)  # Initialize your recommender here\n",
    "\n",
    "# Give the name of your recommender in the line below\n",
    "nn_tts_results = [['NNRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    nn_recommender, interactions_df, items_df))]\n",
    "\n",
    "nn_tts_results = pd.DataFrame(\n",
    "    nn_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(nn_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_tts_results = [['AmazonRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    amazon_recommender, interactions_df, items_df))]\n",
    "\n",
    "amazon_tts_results = pd.DataFrame(\n",
    "    amazon_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(amazon_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.netflix_recommender import NetflixRecommender\n",
    "\n",
    "netflix_recommender = NetflixRecommender(embedding_dim=8, n_epochs=200, print_type='live')\n",
    "\n",
    "netflix_tts_results = [['NetflixRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    netflix_recommender, interactions_df, items_df))]\n",
    "\n",
    "netflix_tts_results = pd.DataFrame(\n",
    "    netflix_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(netflix_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_results = pd.concat([nn_tts_results, amazon_tts_results, netflix_tts_results]).reset_index(drop=True)\n",
    "display(HTML(tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-vegetable",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Write a summary of your experiments. What worked well and what did not? What are your thoughts how could you possibly further improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Functions in data preprocessing and features were improved, but recommender did not work correctly. Neutral network model was created and there was no error, but no matter how scores were calculated in recommend method, quick test of the recommender was showing -1 item ids and array with NaNs.\n",
    "# I think neutral network model should be improved.#\n",
    "###########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
